{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def load_data(file_path):\n",
    "    tokenizer = Tokenizer(filters=\"\")\n",
    "    whole_texts = []\n",
    "    for line in open(file_path, encoding='utf-8'):\n",
    "        whole_texts.append(\"<s> \" + line.strip() + \" </s>\")\n",
    "        \n",
    "    tokenizer.fit_on_texts(whole_texts)\n",
    "    \n",
    "    return tokenizer.texts_to_sequences(whole_texts), tokenizer\n",
    "\n",
    "x_train, tokenizer_en = load_data('./data/small_parallel_enja/train.en')\n",
    "y_train, tokenizer_ja = load_data('./data/small_parallel_enja/train.ja')\n",
    "\n",
    "en_vocab_size = len(tokenizer_en.word_index) + 1\n",
    "ja_vocab_size = len(tokenizer_ja.word_index) + 1\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.02, random_state=42)\n",
    "\n",
    "x_train = pad_sequences(x_train, padding='post')\n",
    "y_train = pad_sequences(y_train, padding='post')\n",
    "\n",
    "seqX_len = len(x_train[0])\n",
    "seqY_len = len(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Permute, Activation, Embedding, Dense, LSTM, concatenate, dot\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "emb_dim = 256\n",
    "hid_dim = 256\n",
    "att_dim = 256\n",
    "\n",
    "encoder_inputs = Input(shape=(seqX_len,))\n",
    "encoder_embedded = Embedding(en_vocab_size, emb_dim, mask_zero=True)(encoder_inputs)\n",
    "encoded_seq, *encoder_states = LSTM(hid_dim, return_sequences=True, return_state=True)(encoder_embedded)\n",
    "\n",
    "decoder_inputs = Input(shape=(seqY_len,))\n",
    "decoder_embedding = Embedding(ja_vocab_size, emb_dim)\n",
    "decoder_embedded = decoder_embedding(decoder_inputs)\n",
    "decoder_lstm = LSTM(hid_dim, return_sequences=True, return_state=True)\n",
    "decoded_seq, _, _ = decoder_lstm(decoder_embedded, initial_state=encoder_states)\n",
    "\n",
    "score_dense = Dense(hid_dim)\n",
    "score = score_dense(decoded_seq)                        # shape: (seqY_len, hid_dim) -> (seqY_len, hid_dim)\n",
    "score = dot([score, encoded_seq], axes=(2,2))           # shape: [(seqY_len, hid_dim), (seqX_len, hid_dim)] -> (seqY_len, seqX_len)\n",
    "attention = Activation('softmax')(score)                # shape: (seqY_len, seqX_len) -> (seqY_len, seqX_len)\n",
    "context = dot([attention, encoded_seq], axes=(2,1))     # shape: [(seqY_len, seqX_len), (seqX_len, hid_dim)] -> (seqY_len, hid_dim)\n",
    "concat = concatenate([context, decoded_seq], axis=2)    # shape: [(seqY_len, hid_dim), (seqY_len, hid_dim)] -> (seqY_len, 2*hid_dim)\n",
    "attention_dense = Dense(att_dim, activation='tanh')\n",
    "attentional = attention_dense(concat)                   # shape: (seqY_len, 2*hid_dim) -> (seqY_len, att_dim)\n",
    "output_dense = Dense(ja_vocab_size, activation='softmax')\n",
    "outputs = output_dense(attentional)                     # shape: (seqY_len, att_dim) -> (seqY_len, ja_vocab_size)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], outputs)\n",
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"775pt\" viewBox=\"0.00 0.00 332.00 775.00\" width=\"332pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 771)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-771 328,-771 328,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 1775011935512 -->\n",
       "<g class=\"node\" id=\"node1\"><title>1775011935512</title>\n",
       "<polygon fill=\"none\" points=\"179.5,-730.5 179.5,-766.5 305.5,-766.5 305.5,-730.5 179.5,-730.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"242.5\" y=\"-744.8\">input_8: InputLayer</text>\n",
       "</g>\n",
       "<!-- 1775011935568 -->\n",
       "<g class=\"node\" id=\"node3\"><title>1775011935568</title>\n",
       "<polygon fill=\"none\" points=\"161,-657.5 161,-693.5 324,-693.5 324,-657.5 161,-657.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"242.5\" y=\"-671.8\">embedding_2: Embedding</text>\n",
       "</g>\n",
       "<!-- 1775011935512&#45;&gt;1775011935568 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>1775011935512-&gt;1775011935568</title>\n",
       "<path d=\"M242.5,-730.313C242.5,-722.289 242.5,-712.547 242.5,-703.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"246,-703.529 242.5,-693.529 239,-703.529 246,-703.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1777229667800 -->\n",
       "<g class=\"node\" id=\"node2\"><title>1777229667800</title>\n",
       "<polygon fill=\"none\" points=\"16.5,-657.5 16.5,-693.5 142.5,-693.5 142.5,-657.5 16.5,-657.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"79.5\" y=\"-671.8\">input_9: InputLayer</text>\n",
       "</g>\n",
       "<!-- 1775011936184 -->\n",
       "<g class=\"node\" id=\"node4\"><title>1775011936184</title>\n",
       "<polygon fill=\"none\" points=\"5,-584.5 5,-620.5 168,-620.5 168,-584.5 5,-584.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-598.8\">embedding_3: Embedding</text>\n",
       "</g>\n",
       "<!-- 1777229667800&#45;&gt;1775011936184 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>1777229667800-&gt;1775011936184</title>\n",
       "<path d=\"M81.1945,-657.313C81.9855,-649.289 82.946,-639.547 83.8312,-630.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"87.323,-630.824 84.8211,-620.529 80.3567,-630.137 87.323,-630.824\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1777229354880 -->\n",
       "<g class=\"node\" id=\"node5\"><title>1777229354880</title>\n",
       "<polygon fill=\"none\" points=\"190.5,-584.5 190.5,-620.5 288.5,-620.5 288.5,-584.5 190.5,-584.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"239.5\" y=\"-598.8\">lstm_2: LSTM</text>\n",
       "</g>\n",
       "<!-- 1775011935568&#45;&gt;1777229354880 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>1775011935568-&gt;1777229354880</title>\n",
       "<path d=\"M241.774,-657.313C241.435,-649.289 241.023,-639.547 240.644,-630.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"244.139,-630.372 240.22,-620.529 237.145,-630.668 244.139,-630.372\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1775011937360 -->\n",
       "<g class=\"node\" id=\"node6\"><title>1775011937360</title>\n",
       "<polygon fill=\"none\" points=\"64.5,-511.5 64.5,-547.5 162.5,-547.5 162.5,-511.5 64.5,-511.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"113.5\" y=\"-525.8\">lstm_3: LSTM</text>\n",
       "</g>\n",
       "<!-- 1775011936184&#45;&gt;1775011937360 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>1775011936184-&gt;1775011937360</title>\n",
       "<path d=\"M93.0359,-584.313C96.1534,-576.115 99.9532,-566.123 103.428,-556.985\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"106.741,-558.12 107.024,-547.529 100.198,-555.632 106.741,-558.12\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1777229354880&#45;&gt;1775011937360 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>1777229354880-&gt;1775011937360</title>\n",
       "<path d=\"M209.32,-584.494C192.456,-574.991 171.24,-563.036 153.061,-552.792\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"154.301,-549.474 143.871,-547.614 150.864,-555.572 154.301,-549.474\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1777323439776 -->\n",
       "<g class=\"node\" id=\"node8\"><title>1777323439776</title>\n",
       "<polygon fill=\"none\" points=\"99,-365.5 99,-401.5 176,-401.5 176,-365.5 99,-365.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"137.5\" y=\"-379.8\">dot_4: Dot</text>\n",
       "</g>\n",
       "<!-- 1777229354880&#45;&gt;1777323439776 -->\n",
       "<g class=\"edge\" id=\"edge9\"><title>1777229354880-&gt;1777323439776</title>\n",
       "<path d=\"M239.5,-455.5C231.559,-430.266 207.827,-412.917 185.252,-401.689\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"186.574,-398.443 176.032,-397.391 183.617,-404.788 186.574,-398.443\" stroke=\"black\"/>\n",
       "<path d=\"M242.777,-584.148C247.268,-556.572 253.309,-501.378 239.5,-457.5\" fill=\"none\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1777318339416 -->\n",
       "<g class=\"node\" id=\"node10\"><title>1777318339416</title>\n",
       "<polygon fill=\"none\" points=\"99,-219.5 99,-255.5 176,-255.5 176,-219.5 99,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"137.5\" y=\"-233.8\">dot_5: Dot</text>\n",
       "</g>\n",
       "<!-- 1777229354880&#45;&gt;1777318339416 -->\n",
       "<g class=\"edge\" id=\"edge12\"><title>1777229354880-&gt;1777318339416</title>\n",
       "<path d=\"M239.5,-455.5C213.765,-387.02 259.171,-354.099 220.5,-292 212.025,-278.391 198.666,-267.585 185.123,-259.351\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"186.669,-256.204 176.245,-254.308 183.211,-262.291 186.669,-256.204\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1775010303504 -->\n",
       "<g class=\"node\" id=\"node7\"><title>1775010303504</title>\n",
       "<polygon fill=\"none\" points=\"74.5,-438.5 74.5,-474.5 178.5,-474.5 178.5,-438.5 74.5,-438.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"126.5\" y=\"-452.8\">dense_3: Dense</text>\n",
       "</g>\n",
       "<!-- 1775011937360&#45;&gt;1775010303504 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>1775011937360-&gt;1775010303504</title>\n",
       "<path d=\"M116.647,-511.313C118.116,-503.289 119.9,-493.547 121.544,-484.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"125.024,-484.996 123.382,-474.529 118.138,-483.735 125.024,-484.996\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1777322443328 -->\n",
       "<g class=\"node\" id=\"node11\"><title>1777322443328</title>\n",
       "<polygon fill=\"none\" points=\"0,-146.5 0,-182.5 173,-182.5 173,-146.5 0,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-160.8\">concatenate_2: Concatenate</text>\n",
       "</g>\n",
       "<!-- 1775011937360&#45;&gt;1777322443328 -->\n",
       "<g class=\"edge\" id=\"edge14\"><title>1775011937360-&gt;1777322443328</title>\n",
       "<path d=\"M94.5684,-511.172C84.7689,-501.355 73.2646,-488.384 65.5,-475 44.2365,-438.347 35.5,-426.875 35.5,-384.5 35.5,-384.5 35.5,-384.5 35.5,-309.5 35.5,-266.133 56.307,-219.417 71.3407,-191.323\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"74.419,-192.988 76.1794,-182.541 68.2881,-189.61 74.419,-192.988\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1775010303504&#45;&gt;1777323439776 -->\n",
       "<g class=\"edge\" id=\"edge8\"><title>1775010303504-&gt;1777323439776</title>\n",
       "<path d=\"M129.163,-438.313C130.406,-430.289 131.915,-420.547 133.306,-411.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"136.789,-411.947 134.862,-401.529 129.872,-410.875 136.789,-411.947\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1777323439944 -->\n",
       "<g class=\"node\" id=\"node9\"><title>1777323439944</title>\n",
       "<polygon fill=\"none\" points=\"63.5,-292.5 63.5,-328.5 211.5,-328.5 211.5,-292.5 63.5,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"137.5\" y=\"-306.8\">activation_2: Activation</text>\n",
       "</g>\n",
       "<!-- 1777323439776&#45;&gt;1777323439944 -->\n",
       "<g class=\"edge\" id=\"edge10\"><title>1777323439776-&gt;1777323439944</title>\n",
       "<path d=\"M137.5,-365.313C137.5,-357.289 137.5,-347.547 137.5,-338.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"141,-338.529 137.5,-328.529 134,-338.529 141,-338.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1777323439944&#45;&gt;1777318339416 -->\n",
       "<g class=\"edge\" id=\"edge11\"><title>1777323439944-&gt;1777318339416</title>\n",
       "<path d=\"M137.5,-292.313C137.5,-284.289 137.5,-274.547 137.5,-265.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"141,-265.529 137.5,-255.529 134,-265.529 141,-265.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1777318339416&#45;&gt;1777322443328 -->\n",
       "<g class=\"edge\" id=\"edge13\"><title>1777318339416-&gt;1777322443328</title>\n",
       "<path d=\"M125.154,-219.313C119.015,-210.766 111.475,-200.269 104.69,-190.823\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"107.409,-188.609 98.732,-182.529 101.723,-192.693 107.409,-188.609\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1777325900856 -->\n",
       "<g class=\"node\" id=\"node12\"><title>1777325900856</title>\n",
       "<polygon fill=\"none\" points=\"34.5,-73.5 34.5,-109.5 138.5,-109.5 138.5,-73.5 34.5,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-87.8\">dense_4: Dense</text>\n",
       "</g>\n",
       "<!-- 1777322443328&#45;&gt;1777325900856 -->\n",
       "<g class=\"edge\" id=\"edge15\"><title>1777322443328-&gt;1777325900856</title>\n",
       "<path d=\"M86.5,-146.313C86.5,-138.289 86.5,-128.547 86.5,-119.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"90.0001,-119.529 86.5,-109.529 83.0001,-119.529 90.0001,-119.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1775000897856 -->\n",
       "<g class=\"node\" id=\"node13\"><title>1775000897856</title>\n",
       "<polygon fill=\"none\" points=\"34.5,-0.5 34.5,-36.5 138.5,-36.5 138.5,-0.5 34.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-14.8\">dense_5: Dense</text>\n",
       "</g>\n",
       "<!-- 1777325900856&#45;&gt;1775000897856 -->\n",
       "<g class=\"edge\" id=\"edge16\"><title>1777325900856-&gt;1775000897856</title>\n",
       "<path d=\"M86.5,-73.3129C86.5,-65.2895 86.5,-55.5475 86.5,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"90.0001,-46.5288 86.5,-36.5288 83.0001,-46.5289 90.0001,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from tensorflow.python.keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 18)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            (None, 18)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 18, 256)      1699072     input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 18, 256)      2246912     input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 18, 256), (N 525312      embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, 18, 256), (N 525312      embedding_3[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 18, 256)      65792       lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_4 (Dot)                     (None, 18, 18)       0           dense_3[0][0]                    \n",
      "                                                                 lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 18, 18)       0           dot_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dot_5 (Dot)                     (None, 18, 256)      0           activation_2[0][0]               \n",
      "                                                                 lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 18, 512)      0           dot_5[0][0]                      \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 18, 256)      131328      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 18, 8777)     2255689     dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 7,449,417\n",
      "Trainable params: 7,449,417\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 39200 samples, validate on 9800 samples\n",
      "Epoch 1/10\n",
      "39200/39200 [==============================] - 63s 2ms/sample - loss: 2.9737 - val_loss: 2.3334\n",
      "Epoch 2/10\n",
      "39200/39200 [==============================] - 67s 2ms/sample - loss: 2.1277 - val_loss: 1.9983\n",
      "Epoch 3/10\n",
      "39200/39200 [==============================] - 69s 2ms/sample - loss: 1.8595 - val_loss: 1.8142\n",
      "Epoch 4/10\n",
      "39200/39200 [==============================] - 73s 2ms/sample - loss: 1.6763 - val_loss: 1.6660\n",
      "Epoch 5/10\n",
      "39200/39200 [==============================] - 78s 2ms/sample - loss: 1.5266 - val_loss: 1.5481\n",
      "Epoch 6/10\n",
      "39200/39200 [==============================] - 82s 2ms/sample - loss: 1.3960 - val_loss: 1.4431\n",
      "Epoch 7/10\n",
      "39200/39200 [==============================] - 88s 2ms/sample - loss: 1.2819 - val_loss: 1.3726\n",
      "Epoch 8/10\n",
      "39200/39200 [==============================] - 91s 2ms/sample - loss: 1.1827 - val_loss: 1.3126\n",
      "Epoch 9/10\n",
      "39200/39200 [==============================] - 97s 2ms/sample - loss: 1.0989 - val_loss: 1.2692\n",
      "Epoch 10/10\n",
      "39200/39200 [==============================] - 97s 2ms/sample - loss: 1.0257 - val_loss: 1.2269\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19dd2b4f7b8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_target = np.hstack((y_train[:, 1:], np.zeros((len(y_train),1), dtype=np.int32)))\n",
    "\n",
    "model.fit([x_train, y_train], np.expand_dims(train_target, -1), batch_size=128, epochs=10, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, [encoded_seq]+encoder_states)\n",
    "\n",
    "decoder_states_inputs = [Input(shape=(hid_dim,)), Input(shape=(hid_dim,))]\n",
    "\n",
    "decoder_inputs = Input(shape=(1,))\n",
    "decoder_embedded = decoder_embedding(decoder_inputs)\n",
    "decoded_seq, *decoder_states = decoder_lstm(decoder_embedded, initial_state=decoder_states_inputs)\n",
    "\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoded_seq] + decoder_states)\n",
    "\n",
    "encoded_seq_in, decoded_seq_in = Input(shape=(seqX_len, hid_dim)), Input(shape=(1, hid_dim))\n",
    "score = score_dense(decoded_seq_in)\n",
    "score = dot([score, encoded_seq_in], axes=(2,2))\n",
    "attention = Activation('softmax')(score)\n",
    "context = dot([attention, encoded_seq_in], axes=(2,1))\n",
    "concat = concatenate([context, decoded_seq_in], axis=2)\n",
    "attentional = attention_dense(concat)\n",
    "attention_outputs = output_dense(attentional)\n",
    "\n",
    "attention_model = Model([encoded_seq_in, decoded_seq_in], [attention_outputs, attention])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq, bos_eos, max_output_length = 1000):\n",
    "    encoded_seq, *states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    target_seq = np.array(bos_eos[0])\n",
    "    output_seq = bos_eos[0][:]\n",
    "    attention_seq = np.empty((0,len(input_seq[0])))\n",
    "    \n",
    "    while True:\n",
    "        decoded_seq, *states_value = decoder_model.predict([target_seq] + states_value)\n",
    "        output_tokens, attention = attention_model.predict([encoded_seq, decoded_seq])\n",
    "        sampled_token_index = [np.argmax(output_tokens[0, -1, :])]\n",
    "        output_seq += sampled_token_index\n",
    "        attention_seq = np.append(attention_seq, attention[0], axis=0)\n",
    "        \n",
    "        if (sampled_token_index == bos_eos[1] or len(output_seq) > max_output_length):\n",
    "            break\n",
    "\n",
    "        target_seq = np.array(sampled_token_index)\n",
    "\n",
    "    return output_seq, attention_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "元の文: <s> you may extend your stay in tokyo . </s>\n",
      "生成文: <s> 東京 で は 、 車 を 持 っ て い い で す よ 。 </s>\n",
      "正解文: <s> 東京 滞在 を 延ば し て も い い で す よ 。 </s>\n",
      "BLEU: 1.459387436556547e-231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suizh\\Anaconda3\\lib\\site-packages\\nltk\\translate\\bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\suizh\\Anaconda3\\lib\\site-packages\\nltk\\translate\\bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\suizh\\Anaconda3\\lib\\site-packages\\nltk\\translate\\bleu_score.py:523: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "detokenizer_en = dict(map(reversed, tokenizer_en.word_index.items()))\n",
    "detokenizer_ja = dict(map(reversed, tokenizer_ja.word_index.items()))\n",
    "\n",
    "text_no = 0\n",
    "input_seq = pad_sequences([x_test[text_no]], seqX_len, padding='post')\n",
    "bos_eos = tokenizer_ja.texts_to_sequences([\"<s>\", \"</s>\"])\n",
    "\n",
    "output_seq, attention_seq = decode_sequence(input_seq, bos_eos)\n",
    "prediction = [detokenizer_ja[i] for i in output_seq]\n",
    "reference = [detokenizer_ja[i] for i in y_test[text_no]]\n",
    "\n",
    "print('元の文:', ' '.join([detokenizer_en[i] for i in x_test[text_no]]))\n",
    "print('生成文:', ' '.join(prediction))\n",
    "print('正解文:', ' '.join(reference))\n",
    "print('BLEU:', sentence_bleu(reference, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "元の文: <s> i study at school . </s>\n",
      "生成文: <s> 私 は 学校 に 勉強 し ま す 。 </s>\n",
      "正解文: <s> 私 は 学校 で 勉強 する 。 </s>\n",
      "BLEU: 1.4147351699132998e-231\n"
     ]
    }
   ],
   "source": [
    "text_no = 1\n",
    "input_seq = pad_sequences([x_test[text_no]], seqX_len, padding='post')\n",
    "\n",
    "output_seq, attention_seq = decode_sequence(input_seq, bos_eos)\n",
    "prediction = [detokenizer_ja[i] for i in output_seq]\n",
    "reference = [detokenizer_ja[i] for i in y_test[text_no]]\n",
    "\n",
    "print('元の文:', ' '.join([detokenizer_en[i] for i in x_test[text_no]]))\n",
    "print('生成文:', ' '.join(prediction))\n",
    "print('正解文:', ' '.join(reference))\n",
    "print('BLEU:', sentence_bleu(reference, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "heatmap = ax.pcolor(attention_seq[:,:len(x_test[text_no])], cmap=plt.cm.Blues, vmax=1)\n",
    "ax.set_xticks(np.arange(len(x_test[text_no])) + 0.5, minor=False)\n",
    "ax.set_yticks(np.arange(attention_seq.shape[0]) + 0.5, minor=False)\n",
    "ax.invert_yaxis()\n",
    "ax.xaxis.tick_top()\n",
    "ax.set_xticklabels([detokenizer_en[i] for i in x_test[text_no]], minor=False)\n",
    "ax.set_yticklabels([detokenizer_ja[i] for i in output_seq[1:]], minor=False)\n",
    "plt.colorbar(heatmap)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
