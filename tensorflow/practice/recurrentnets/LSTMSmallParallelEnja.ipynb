{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def load_data(file_path):\n",
    "    tokenizer = Tokenizer(filters=\"\")\n",
    "    whole_texts = []\n",
    "    for line in open(file_path, encoding='utf-8'):\n",
    "        whole_texts.append(\"<s> \" + line.strip() + \" </s>\")\n",
    "        \n",
    "    tokenizer.fit_on_texts(whole_texts)\n",
    "    \n",
    "    return tokenizer.texts_to_sequences(whole_texts), tokenizer\n",
    "\n",
    "# download from https://github.com/odashi/small_parallel_enja\n",
    "x_train, tokenizer_en = load_data('./data/small_parallel_enja/train.en')\n",
    "y_train, tokenizer_ja = load_data('./data/small_parallel_enja/train.ja')\n",
    "\n",
    "en_vocab_size = len(tokenizer_en.word_index) + 1\n",
    "ja_vocab_size = len(tokenizer_ja.word_index) + 1\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.02, random_state=42)\n",
    "\n",
    "# パディング\n",
    "x_train = pad_sequences(x_train, padding='post')\n",
    "y_train = pad_sequences(y_train, padding='post')\n",
    "\n",
    "seqX_len = len(x_train[0])\n",
    "seqY_len = len(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, LSTM\n",
    "\n",
    "emb_dim = 256\n",
    "hid_dim = 256\n",
    "\n",
    "encoder_inputs = Input(shape=(seqX_len,))\n",
    "# (seqX_len,)\n",
    "encoder_embedded = Embedding(en_vocab_size, emb_dim, mask_zero=True)(encoder_inputs)\n",
    "# (seqX_len, emb_dim)\n",
    "_, *encoder_states = LSTM(hid_dim, return_state=True)(encoder_embedded)  \n",
    "# (hid_dim, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(seqY_len,))\n",
    "# (seqY_len,)\n",
    "decoder_embedding = Embedding(ja_vocab_size, emb_dim)\n",
    "decoder_embedded = decoder_embedding(decoder_inputs)\n",
    "# (seqY_len, emb_dim)\n",
    "decoder_lstm = LSTM(hid_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedded, initial_state=encoder_states)\n",
    "# (seqY_len, hid_dim)\n",
    "decoder_dense = Dense(ja_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "# (seqY_len, ja_vocab_size)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_14 (InputLayer)           (None, 18)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_15 (InputLayer)           (None, 18)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 18, 256)      1699072     input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 18, 256)      2246912     input_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   [(None, 256), (None, 525312      embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                   [(None, 18, 256), (N 525312      embedding_6[0][0]                \n",
      "                                                                 lstm_5[0][1]                     \n",
      "                                                                 lstm_5[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 18, 8777)     2255689     lstm_6[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 7,252,297\n",
      "Trainable params: 7,252,297\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"337pt\" viewBox=\"0.00 0.00 332.00 337.00\" width=\"332pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 333)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-333 328,-333 328,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 2084602128816 -->\n",
       "<g class=\"node\" id=\"node1\"><title>2084602128816</title>\n",
       "<polygon fill=\"none\" points=\"15,-292.5 15,-328.5 148,-328.5 148,-292.5 15,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"81.5\" y=\"-306.8\">input_14: InputLayer</text>\n",
       "</g>\n",
       "<!-- 2084602128984 -->\n",
       "<g class=\"node\" id=\"node3\"><title>2084602128984</title>\n",
       "<polygon fill=\"none\" points=\"0,-219.5 0,-255.5 163,-255.5 163,-219.5 0,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"81.5\" y=\"-233.8\">embedding_5: Embedding</text>\n",
       "</g>\n",
       "<!-- 2084602128816&#45;&gt;2084602128984 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>2084602128816-&gt;2084602128984</title>\n",
       "<path d=\"M81.5,-292.313C81.5,-284.289 81.5,-274.547 81.5,-265.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"85.0001,-265.529 81.5,-255.529 78.0001,-265.529 85.0001,-265.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2084605393496 -->\n",
       "<g class=\"node\" id=\"node2\"><title>2084605393496</title>\n",
       "<polygon fill=\"none\" points=\"181,-219.5 181,-255.5 314,-255.5 314,-219.5 181,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"247.5\" y=\"-233.8\">input_15: InputLayer</text>\n",
       "</g>\n",
       "<!-- 2084605394616 -->\n",
       "<g class=\"node\" id=\"node4\"><title>2084605394616</title>\n",
       "<polygon fill=\"none\" points=\"161,-146.5 161,-182.5 324,-182.5 324,-146.5 161,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"242.5\" y=\"-160.8\">embedding_6: Embedding</text>\n",
       "</g>\n",
       "<!-- 2084605393496&#45;&gt;2084605394616 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>2084605393496-&gt;2084605394616</title>\n",
       "<path d=\"M246.29,-219.313C245.725,-211.289 245.039,-201.547 244.406,-192.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"247.893,-192.258 243.699,-182.529 240.91,-192.75 247.893,-192.258\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2084602129040 -->\n",
       "<g class=\"node\" id=\"node5\"><title>2084602129040</title>\n",
       "<polygon fill=\"none\" points=\"36.5,-146.5 36.5,-182.5 134.5,-182.5 134.5,-146.5 36.5,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"85.5\" y=\"-160.8\">lstm_5: LSTM</text>\n",
       "</g>\n",
       "<!-- 2084602128984&#45;&gt;2084602129040 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>2084602128984-&gt;2084602129040</title>\n",
       "<path d=\"M82.4683,-219.313C82.9203,-211.289 83.4692,-201.547 83.975,-192.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"87.4725,-192.71 84.5406,-182.529 80.4836,-192.316 87.4725,-192.71\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2082026973672 -->\n",
       "<g class=\"node\" id=\"node6\"><title>2082026973672</title>\n",
       "<polygon fill=\"none\" points=\"114.5,-73.5 114.5,-109.5 212.5,-109.5 212.5,-73.5 114.5,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"163.5\" y=\"-87.8\">lstm_6: LSTM</text>\n",
       "</g>\n",
       "<!-- 2084605394616&#45;&gt;2082026973672 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>2084605394616-&gt;2082026973672</title>\n",
       "<path d=\"M223.376,-146.313C213.381,-137.33 200.99,-126.193 190.077,-116.386\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"192.225,-113.61 182.448,-109.529 187.546,-118.816 192.225,-113.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2084602129040&#45;&gt;2082026973672 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>2084602129040-&gt;2082026973672</title>\n",
       "<path d=\"M104.382,-146.313C114.25,-137.33 126.485,-126.193 137.259,-116.386\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"139.753,-118.849 144.792,-109.529 135.041,-113.672 139.753,-118.849\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2084603714472 -->\n",
       "<g class=\"node\" id=\"node7\"><title>2084603714472</title>\n",
       "<polygon fill=\"none\" points=\"111.5,-0.5 111.5,-36.5 215.5,-36.5 215.5,-0.5 111.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"163.5\" y=\"-14.8\">dense_2: Dense</text>\n",
       "</g>\n",
       "<!-- 2082026973672&#45;&gt;2084603714472 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>2082026973672-&gt;2084603714472</title>\n",
       "<path d=\"M163.5,-73.3129C163.5,-65.2895 163.5,-55.5475 163.5,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"167,-46.5288 163.5,-36.5288 160,-46.5289 167,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from tensorflow.python.keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 39200 samples, validate on 9800 samples\n",
      "Epoch 1/15\n",
      "39200/39200 [==============================] - 61s 2ms/sample - loss: 2.9791 - val_loss: 2.3208\n",
      "Epoch 2/15\n",
      "39200/39200 [==============================] - 68s 2ms/sample - loss: 2.0854 - val_loss: 1.9475\n",
      "Epoch 3/15\n",
      "39200/39200 [==============================] - 98s 2ms/sample - loss: 1.8194 - val_loss: 1.7838\n",
      "Epoch 4/15\n",
      "39200/39200 [==============================] - 106s 3ms/sample - loss: 1.6552 - val_loss: 1.6562\n",
      "Epoch 5/15\n",
      "39200/39200 [==============================] - 136s 3ms/sample - loss: 1.5253 - val_loss: 1.5614\n",
      "Epoch 6/15\n",
      "39200/39200 [==============================] - 124s 3ms/sample - loss: 1.4161 - val_loss: 1.4829\n",
      "Epoch 7/15\n",
      "39200/39200 [==============================] - 104s 3ms/sample - loss: 1.3221 - val_loss: 1.4237\n",
      "Epoch 8/15\n",
      "39200/39200 [==============================] - 134s 3ms/sample - loss: 1.2395 - val_loss: 1.3746\n",
      "Epoch 9/15\n",
      "39200/39200 [==============================] - 128s 3ms/sample - loss: 1.1659 - val_loss: 1.3338\n",
      "Epoch 10/15\n",
      "39200/39200 [==============================] - 103s 3ms/sample - loss: 1.1010 - val_loss: 1.3049\n",
      "Epoch 11/15\n",
      "39200/39200 [==============================] - 138s 4ms/sample - loss: 1.0433 - val_loss: 1.2816\n",
      "Epoch 12/15\n",
      "39200/39200 [==============================] - 121s 3ms/sample - loss: 0.9913 - val_loss: 1.2641\n",
      "Epoch 13/15\n",
      "39200/39200 [==============================] - 110s 3ms/sample - loss: 0.9442 - val_loss: 1.2567\n",
      "Epoch 14/15\n",
      "39200/39200 [==============================] - 140s 4ms/sample - loss: 0.8995 - val_loss: 1.2490\n",
      "Epoch 15/15\n",
      "39200/39200 [==============================] - 112s 3ms/sample - loss: 0.8586 - val_loss: 1.2472\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e55dc61cc0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_target = np.hstack((y_train[:, 1:], np.zeros((len(y_train),1), dtype=np.int32)))\n",
    "\n",
    "model.fit([x_train, y_train], np.expand_dims(train_target, -1), batch_size=128, epochs=15, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_states_inputs = [Input(shape=(hid_dim,)), Input(shape=(hid_dim,))]\n",
    "decoder_inputs = Input(shape=(1,))\n",
    "decoder_embedded = decoder_embedding(decoder_inputs)\n",
    "decoder_outputs, *decoder_states = decoder_lstm(decoder_embedded, initial_state=decoder_states_inputs)\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq, bos_eos, max_output_length = 1000):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    target_seq = np.array(bos_eos[0])\n",
    "    output_seq= bos_eos[0][:]\n",
    "    \n",
    "    while True:\n",
    "        output_tokens, *states_value = decoder_model.predict([target_seq] + states_value)\n",
    "        sampled_token_index = [np.argmax(output_tokens[0, -1, :])]\n",
    "        output_seq += sampled_token_index\n",
    "        \n",
    "        if (sampled_token_index == bos_eos[1] or len(output_seq) > max_output_length):\n",
    "            break\n",
    "\n",
    "        target_seq = np.array(sampled_token_index)\n",
    "\n",
    "    return output_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "元の文: <s> you may extend your stay in tokyo . </s>\n",
      "生成文: <s> あなた は 東京 に 何 を も っ て い い で す か 。 </s>\n",
      "正解文: <s> 東京 滞在 を 延ば し て も い い で す よ 。 </s>\n"
     ]
    }
   ],
   "source": [
    "detokenizer_en = dict(map(reversed, tokenizer_en.word_index.items()))\n",
    "detokenizer_ja = dict(map(reversed, tokenizer_ja.word_index.items()))\n",
    "\n",
    "text_no = 0\n",
    "input_seq = pad_sequences([x_test[text_no]], seqX_len, padding='post')\n",
    "bos_eos = tokenizer_ja.texts_to_sequences([\"<s>\", \"</s>\"])\n",
    "\n",
    "print('元の文:', ' '.join([detokenizer_en[i] for i in x_test[text_no]]))\n",
    "print('生成文:', ' '.join([detokenizer_ja[i] for i in decode_sequence(input_seq, bos_eos)]))\n",
    "print('正解文:', ' '.join([detokenizer_ja[i] for i in y_test[text_no]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5506953149031837\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "prediction = ['I', 'am', 'a', 'graduate', 'student', 'at', 'a', 'university']\n",
    "reference = [['I', 'am', 'a', 'graduate', 'student', 'at', 'the', 'university', 'of', 'tokyo']]\n",
    "\n",
    "print(sentence_bleu(reference, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', '私', 'は', '学校', 'に', '行', 'き', 'ま', 'す', '。', '</s>']\n",
      "[['<s>', '私', 'は', '学校', 'で', '勉強', 'する', '。', '</s>']]\n",
      "0.2790159393585827\n"
     ]
    }
   ],
   "source": [
    "text_no = 1\n",
    "input_seq = pad_sequences([x_test[text_no]], seqX_len, padding='post')\n",
    "bos_eos = tokenizer_ja.texts_to_sequences([\"<s>\", \"</s>\"])\n",
    "\n",
    "prediction = [detokenizer_ja[i] for i in decode_sequence(input_seq, bos_eos)]\n",
    "reference = [[detokenizer_ja[i] for i in y_test[text_no]]]\n",
    "\n",
    "print(prediction)\n",
    "print(reference)\n",
    "\n",
    "print(sentence_bleu(reference, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
